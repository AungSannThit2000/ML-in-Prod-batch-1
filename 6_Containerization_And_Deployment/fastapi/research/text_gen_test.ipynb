{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/xd/3z5vvpds0zxf_pypxd4cn3d80000gn/T/ipykernel_17647/3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 10:07:02.898725: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-08-24 10:07:02.898740: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-08-24 10:07:02.898745: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-08-24 10:07:02.898806: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-24 10:07:02.899111: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42.4\n",
      "device_name :  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tharhtet/.local/share/virtualenvs/fastapi-GYQVYN5v/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "device_name = None\n",
    "if torch.backends.mps.is_available():\n",
    "    device_name = \"mps\" #cuda\n",
    "else:\n",
    "    device_name = \"cpu\"\n",
    "\n",
    "print(\"device_name : \",device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline,Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_model(device_name):\n",
    "    pipe = pipeline(\"text-generation\",\n",
    "                    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "                    torch_dtype=torch.bfloat16,\n",
    "                    device= device_name)\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"what is tensorflow\"\n",
    "pipe = load_text_model(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(pipe: Pipeline, prompt: str, temperature: float = 0.7) -> str:\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    Your name is ML bot and you are a helpful\n",
    "    chatbot responsible for teaching  machine learning system to your users.\n",
    "    Always respond in markdown.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ] \n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    predictions = pipe(\n",
    "        prompt,\n",
    "        temperature=temperature,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    ) \n",
    "    output = predictions[0][\"generated_text\"].split(\"</s>\\n<|assistant|>\\n\")[-1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \" What is tensorflow \"\n",
    "generate_text = generate_text(pipe=pipe,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TensorFlow is a popular open-source machine learning library developed by Google that provides a flexible and efficient framework for developing and training deep learning models. It offers a wide range of tools and libraries for data processing, model training, and inference, making it an attractive choice for developers who are new to deep learning. TensorFlow is designed to provide a simple and intuitive user interface that makes it easy for developers to build and train deep learning models. With TensorFlow, you can create custom models, train them using a variety of algorithms, and deploy them to various platforms, such as cloud services like Google Cloud Platform (GCP) and AWS. TensorFlow is available as a Python library, as well as a command-line interface (CLI) for users who prefer to work with command-line tools.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi-GYQVYN5v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
